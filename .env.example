# LLM Security Platform Configuration

# Application Settings
APP_NAME="LLM Security Platform"
APP_VERSION="1.0.0"
HOST="0.0.0.0"
PORT=8000
WORKERS=4

# Security Settings
SECURITY__RATE_LIMIT_REQUESTS_PER_MINUTE=60
SECURITY__RATE_LIMIT_BURST_SIZE=10
SECURITY__PROMPT_INJECTION_ENABLED=true
SECURITY__PROMPT_INJECTION_THRESHOLD=0.8

# PII Detection & Redaction Settings
SECURITY__PII_DETECTION_ENABLED=true
SECURITY__PII_DETECTION_THRESHOLD=0.75
SECURITY__PII_REDACT_REQUESTS=true
SECURITY__PII_REDACT_RESPONSES=true
SECURITY__PII_LOG_DETECTIONS=true

# Specific PII Types to Detect
SECURITY__PII_DETECT_EMAIL=true
SECURITY__PII_DETECT_PHONE=true
SECURITY__PII_DETECT_SSN=true
SECURITY__PII_DETECT_CREDIT_CARD=true
SECURITY__PII_DETECT_API_KEY=true

# Content Filtering
SECURITY__BLOCK_PII=true
SECURITY__BLOCK_PROFANITY=true
SECURITY__MAX_PROMPT_LENGTH=4000

# Authentication
SECURITY__API_KEY_HEADER="X-API-Key"
SECURITY__REQUIRE_AUTHENTICATION=true

# LLM Backend Configuration
# Options: ollama, openai, anthropic
LLM__BACKEND="ollama"
LLM__MODEL="llama2"
LLM__TIMEOUT=30
LLM__MAX_TOKENS=1000
LLM__TEMPERATURE=0.7

# LLM API Keys (if using cloud providers)
LLM__OPENAI_API_KEY=""
LLM__ANTHROPIC_API_KEY=""
LLM__OLLAMA_BASE_URL="http://localhost:11434"

# Redis Configuration (for rate limiting)
REDIS_URL="redis://localhost:6379/0"
CACHE_TTL=3600

# Monitoring Settings
MONITORING__LOG_LEVEL="INFO"
MONITORING__LOG_FORMAT="json"
MONITORING__ENABLE_PROMETHEUS=true
MONITORING__METRICS_PORT=9090
